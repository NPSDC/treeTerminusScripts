### Adapted from
### https://gist.github.com/mikelove/5a8134e57f652f970f1a176efc900cbe
### https://www.sichong.site/2020/02/25/snakemake-and-slurm-how-to-manage-workflow-with-resource-constraint-on-hpc/

import yaml
with open('cluster_partition.conf', 'r') as f:
    partitions = yaml.safe_load(f)

def get_partition(rule_name):
    return partitions[rule_name] if rule_name in partitions else partitions['__default__']

configfile:
    "config.json"
RUNS, = glob_wildcards(config['bam_path'] + "/{run}.bam")

rule all:
    input: config['multiqc_path'] + "/multiqc_report.html"

rule conv_bam:
    input:
        inp_bam = config['bam_path'] + "/{sample}.bam"
    output:
        out_fastq = config['fastq_path'] + "/{sample}.fastq"
    params:
        bed_path = config['bed_path'],
        partition = get_partition('conv_bam')
    shell:
        """
            export PATH=$PATH:{params.bed_path}
            bamToFastq -i {input.inp_bam} -fq {output.out_fastq}
        """

rule build_sal_ind:
    input:
        inp_whole_fasta = config['ind_path'] + "/" + config['chimp_genome_fa'],
        inp_whole_cdna = config['ind_path'] + "/" + config['chimp_cdna_fa'],
        inp_whole_ncrna = config['ind_path'] + "/" + config['chimp_ncrna_fa']
        
    output:
        config['ind_path'] + "/sal_ind/pos.bin"
    params:
        ind_path = config['ind_path'],
        inp_sal_ind = config['ind_path'] + "/sal_ind",
        partition = get_partition('build_sal_ind')
    resources:cpus=10, mem=32000
    conda:
        "env.yml"
    shell:
        """
            grep "^>" <(gunzip -c {input.inp_whole_fasta}) | cut -d " " -f 1 > decoys.txt
            sed -i.bak -e 's/>//g' decoys.txt
            cat {input.inp_whole_cdna} {input.inp_whole_ncrna} {input.inp_whole_fasta} > gentrome.fa.gz
            salmon index -t gentrome.fa.gz -d decoys.txt -p {resources.cpus} -i {params.inp_sal_ind} --gencode
            rm decoys.txt gentrome.fa.gz
        """

rule run_salmon:
    input:
        inp_fastq = config['fastq_path'] + "/{sample}.fastq"
    output:
        out_sal = config['out_sal'] + "/{sample}/quant.sf"
    resources: cpus=10, mem=32000
    params:
        out_dir = config['out_sal'] + "/{sample}",
        index = config['ind_path'] + "/sal_ind",
        partition = get_partition('run_salmon')
        #partition = "throughput"
    conda:
        "env.yml"
    shell:
        "salmon quant -i {params.index} -l A -p {resources.cpus} --gcBias "
        "--numGibbsSamples 100 --thinningFactor 100 -d "
        "-o {params.out_dir} -r {input.inp_fastq}"

rule fastqc:
    input:
        inp_fastq = config['fastq_path'] + "/{sample}.fastq"
    output:
        config['fastqc_path'] + "/{sample}/{sample}_fastqc.html"
    resources: cpus=10
    params:
        dir = config['fastqc_path'] + "/{sample}",
        partition = get_partition('fastqc')
    shell:
        """
            module load fastqc
            fastqc --quiet -t {resources.cpus} --outdir {params.dir} {input}
        """

rule multiqc:
    input:
        expand([config['out_sal'] + "/{run}/quant.sf",
                config['fastqc_path'] + "/{run}/{run}_fastqc.html"],
               run=RUNS)
    output:
        config['multiqc_path'] + "/multiqc_report.html"
    params:
        partition = get_partition('multiqc'),
        output = config['multiqc_path']
    shell:
        """
            module load multiqc
            multiqc . -o {params.output}
        """

rule run_terminus:
    input:
        p1 = expand(config['out_term'] + "/{run}/groups.txt",run=RUNS),
        p2 = config['out_term'] + "/cluster_nwk.txt"
    params:
        partition = get_partition('run_terminus')

rule run_term_group:
    input:
        config['out_sal'] + "/{run}"
    output:
        config['out_term'] + "/{run}/groups.txt"
    params:
        term_path=config["term_path"] + "/target/release/terminus",
        partition = get_partition('run_term_group'),
        output = config['out_term']
    shell:
        "{params.term_path} group -m 0.1 --tolerance 0.001 -d {input} -o {params.output}"

rule run_term_collpase:
    input:
        config['out_sal']
    output:
        config['out_term'] + "/cluster_nwk.txt"
    params:
        term_path=config["term_path"],
        output = config['out_term'],
        partition = get_partition('run_term_collapse')
    shell:
        """
            cd {params.term_path}
            target/release/terminus collapse -c 0 -d {input} -o {params.output} -m true --merge_type phylip
            cd -
        """
